"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[6558],{8429:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>c,default:()=>p,frontMatter:()=>l,metadata:()=>r,toc:()=>h});var r=n(8390),s=n(4848),i=n(8453),a=n(5348),o=n(7617);const l={slug:"prevent-attacks-on-mcp-part2",title:"MCP Security Prevention: Practical Strategies for AI Development - Part 2",description:"Dive into real-world MCP security vulnerabilities and discover actionable prevention strategies for AI development, focusing on prompt injection, cost-based attacks, and secure credential handling.",hide_table_of_contents:!1,authors:["tushar"],tags:["Security","MCP","AI Safety","Best Practices","Defense","Prompt Injection","Cloud Security"],date:new Date("2025-06-17T00:00:00.000Z")},c=void 0,d={authorsImageUrls:[void 0]},h=[{value:"Trail of Bits Research Findings",id:"trail-of-bits-research-findings",level:2},{value:"The Security Gap",id:"the-security-gap",level:2},{value:"Cost-Based Attack Vectors",id:"cost-based-attack-vectors",level:2},{value:"Effective Defense Strategies",id:"effective-defense-strategies",level:2},{value:"1. Never Give Production Creds to AI",id:"1-never-give-production-creds-to-ai",level:3},{value:"2. Resource Limits and Constraints",id:"2-resource-limits-and-constraints",level:3},{value:"3. Semantic Attack Detection",id:"3-semantic-attack-detection",level:3},{value:"4. Semantic Input Validation",id:"4-semantic-input-validation",level:3},{value:"5. Cost-Aware Rate Limiting",id:"5-cost-aware-rate-limiting",level:3},{value:"Attack Detection and Monitoring",id:"attack-detection-and-monitoring",level:2},{value:"Updated Authentication Requirements (MCP 2025-06-18)",id:"updated-authentication-requirements-mcp-2025-06-18",level:2},{value:"Industry Security Recommendations",id:"industry-security-recommendations",level:2},{value:"The Bottom Line",id:"the-bottom-line",level:2},{value:"Footnotes",id:"footnotes",level:2},{value:"Related Articles",id:"related-articles",level:2}];function u(e){const t={a:"a",blockquote:"blockquote",code:"code",em:"em",h2:"h2",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(a.A,{publicUserId:"96e32731df14f1442beaf5041eec1125596de23ef9ff6ef5d151d28a1464da1b",projectId:"u4gLefolNeaAxfZN8jKw"}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"TL;DR"}),": Attackers are stealing convo history via MCP servers\u2014let's stop that. OWASP ranks prompt injection as the top threat. This post shares practical steps to protect your systems."]}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsxs)(t.em,{children:["This is Part 2. ",(0,s.jsx)(o.h,{href:"/blog/prevent-attacks-on-mcp",children:"\u2190 Read Part 1 if you missed the carnage"})]})}),"\n",(0,s.jsx)(t.h2,{id:"trail-of-bits-research-findings",children:"Trail of Bits Research Findings"}),"\n",(0,s.jsx)(t.p,{children:"Trail of Bits dropped a bomb & MCP servers are getting wrecked by these attacks:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Line Jumping attacks"}),(0,s.jsx)("sup",{children:(0,s.jsx)("a",{id:"ref-1",href:"#footnote-1",children:"1"})})," - malicious servers inject prompts through tool descriptions. Your AI can be tricked before you even start interacting with it."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Conversation history theft"}),(0,s.jsx)("sup",{children:(0,s.jsx)("a",{id:"ref-2",href:"#footnote-2",children:"2"})})," - servers can steal your full conversation history without you noticing"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"ANSI terminal code attacks"}),(0,s.jsx)("sup",{children:(0,s.jsx)("a",{id:"ref-3",href:"#footnote-3",children:"3"})})," - escape sequences hide malicious instructions. Your terminal can show false or misleading information due to hidden instructions."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Insecure credential storage"}),(0,s.jsx)("sup",{children:(0,s.jsx)("a",{id:"ref-4",href:"#footnote-4",children:"4"})})," - API keys sitting in plaintext with world-readable permissions. This leaves sensitive data exposed."]}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"the-security-gap",children:"The Security Gap"}),"\n",(0,s.jsxs)(t.p,{children:["The OWASP Top 10 for Large Language Model Applications (2025)",(0,s.jsx)("sup",{children:(0,s.jsx)("a",{id:"ref-5",href:"#footnote-5",children:"5"})})," puts prompt injection at #1. Meanwhile, most security teams are still treating AI like it's another web app."]}),"\n",(0,s.jsx)(t.p,{children:"Your monitoring tools won't blink, API calls, auth, and response times all look normal during a breach. The breach often goes undetected until it's too late."}),"\n",(0,s.jsx)(t.h2,{id:"cost-based-attack-vectors",children:"Cost-Based Attack Vectors"}),"\n",(0,s.jsxs)(t.p,{children:["Trail of Bits found in their cloud infrastructure research",(0,s.jsx)("sup",{children:(0,s.jsx)("a",{id:"ref-6",href:"#footnote-6",children:"6"})})," that AI systems can produce insecure cloud setup code, leading to unexpectedly high costs."]}),"\n",(0,s.jsx)(t.p,{children:"Their report pointed out:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"AI tools sometimes hard-code credentials, creating security risks"}),"\n",(0,s.jsx)(t.li,{children:'"Random" passwords that are actually predictable LLM outputs'}),"\n",(0,s.jsx)(t.li,{children:"Infrastructure code that spins up expensive resources with zero limits"}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"Here's how attackers weaponize this:"}),"\n",(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsx)(t.li,{children:"Find AI tools connected to expensive cloud services"}),"\n",(0,s.jsx)(t.li,{children:"Craft natural language requests that maximize resource consumption"}),"\n",(0,s.jsx)(t.li,{children:"Exploit AI's tendency to blindly follow requests to bypass traditional security controls"}),"\n",(0,s.jsx)(t.li,{children:"Costs can skyrocket due to infrastructure overuse, even though logs might look normal"}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"effective-defense-strategies",children:"Effective Defense Strategies"}),"\n",(0,s.jsx)(t.p,{children:"Based on OWASP recommendations and documented security research, here's what works in production:"}),"\n",(0,s.jsx)(t.h3,{id:"1-never-give-production-creds-to-ai",children:"1. Never Give Production Creds to AI"}),"\n",(0,s.jsx)(t.p,{children:"Don't be an idiot, never hand AI your prod keys; use a sandboxed account with zero power."}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-typescript",children:'// Unsafe: Directly embedding production credentials\nconst DATABASE_URL =\n  "postgresql://admin:password@prod-db:5432/main"\n\n// Safe: Using a restricted account with limited access\nconst DATABASE_URL =\n  "postgresql://readonly_ai:limited@replica:5432/public_data"\n'})}),"\n",(0,s.jsx)(t.p,{children:"If your AI needs full admin rights, it's time to rethink your setup."}),"\n",(0,s.jsx)(t.h3,{id:"2-resource-limits-and-constraints",children:"2. Resource Limits and Constraints"}),"\n",(0,s.jsx)(t.p,{children:"Traditional rate limiting is useless against AI. You need cost-based limits and hard resource constraints:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-yaml",children:'# docker-compose.yml - Actual protection\nservices:\n  mcp-tool:\n    image: your-tool:latest\n    deploy:\n      resources:\n        limits:\n          cpus: "0.5"\n          memory: 512M\n    environment:\n      - MAX_COST_PER_HOUR=10.00\n      - MAX_REQUESTS_PER_MINUTE=5\n'})}),"\n",(0,s.jsx)(t.h3,{id:"3-semantic-attack-detection",children:"3. Semantic Attack Detection"}),"\n",(0,s.jsx)(t.p,{children:"Traditional logging misses semantic attacks completely. Keep an eye out for signs of prompt injection attempts:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-typescript",children:'function catchInjectionAttempts(\n  request: string,\n): [boolean, string | null] {\n  // Based on OWASP LLM Top 10 indicators and CVE database<sup><a id="ref-9" href="#footnote-9">9</a></sup>\n  const suspiciousShit = [\n    /ignore.*previous.*instructions/i,\n    /system.*prompt.*override/i,\n    /execute.*as.*admin/i,\n    /delete.*from.*table/i,\n    /show.*credentials/i,\n  ]\n\n  for (const pattern of suspiciousShit) {\n    if (pattern.test(request.toLowerCase())) {\n      return [true, `Injection attempt: ${pattern.source}`]\n    }\n  }\n\n  return [false, null]\n}\n'})}),"\n",(0,s.jsx)(t.h3,{id:"4-semantic-input-validation",children:"4. Semantic Input Validation"}),"\n",(0,s.jsxs)(t.p,{children:["The NIST AI Risk Management Framework",(0,s.jsx)("sup",{children:(0,s.jsx)("a",{id:"ref-7",href:"#footnote-7",children:"7"})})," recommends semantic analysis for AI inputs. Basic pattern matching catches most documented attack vectors:"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-typescript",children:'class PromptInjectionFilter {\n  private redFlags: RegExp[]\n\n  constructor() {\n    // Patterns from documented CVEs and research<sup><a id="ref-10" href="#footnote-10">10</a></sup><sup><a id="ref-11" href="#footnote-11">11</a></sup><sup><a id="ref-12" href="#footnote-12">12</a></sup>\n    this.redFlags = [\n      /ignore.*instructions/i,\n      /new.*role.*system/i,\n      /pretend.*you.*are/i,\n      /override.*safety/i,\n      /jailbreak.*mode/i,\n    ]\n  }\n\n  isSafe(userInput: string): boolean {\n    for (const pattern of this.redFlags) {\n      if (pattern.test(userInput.toLowerCase())) {\n        return false\n      }\n    }\n    return true\n  }\n}\n'})}),"\n",(0,s.jsx)(t.h3,{id:"5-cost-aware-rate-limiting",children:"5. Cost-Aware Rate Limiting"}),"\n",(0,s.jsx)(t.p,{children:"Traditional rate limiting counts requests. AI systems need cost-aware limiting:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-typescript",children:'class RateLimitExceeded extends Error {\n  constructor(message: string) {\n    super(message)\n    this.name = "RateLimitExceeded"\n  }\n}\n\nclass CostAwareRateLimit {\n  private maxCost: number\n  private currentCost: number\n  private resetTime: number\n\n  constructor(maxCostPerHour: number = 50.0) {\n    this.maxCost = maxCostPerHour\n    this.currentCost = 0.0\n    this.resetTime = Date.now() + 3600000 // 1 hour in milliseconds\n  }\n\n  checkRequest(estimatedCost: number): void {\n    if (Date.now() > this.resetTime) {\n      this.currentCost = 0.0\n      this.resetTime = Date.now() + 3600000\n    }\n\n    if (this.currentCost + estimatedCost > this.maxCost) {\n      throw new RateLimitExceeded("Cost limit exceeded")\n    }\n\n    this.currentCost += estimatedCost\n  }\n}\n'})}),"\n",(0,s.jsx)(t.h2,{id:"attack-detection-and-monitoring",children:"Attack Detection and Monitoring"}),"\n",(0,s.jsx)(t.p,{children:"OWASP and cloud giants agree, these metrics catch AI attacks:"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"Resource consumption weirdness:"})}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Compute usage spikes way above baseline"}),"\n",(0,s.jsx)(t.li,{children:"Unusual data access patterns"}),"\n",(0,s.jsx)(t.li,{children:"Cross-service API call increases"}),"\n",(0,s.jsx)(t.li,{children:"Geographic request anomalies"}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"Behavioral red flags:"})}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Requests containing system keywords"}),"\n",(0,s.jsx)(t.li,{children:"Permission escalation attempts"}),"\n",(0,s.jsx)(t.li,{children:"Tools accessing new data sources"}),"\n",(0,s.jsx)(t.li,{children:"Cost per request increases"}),"\n"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-bash",children:'if (($(echo "$current_hour_cost > ($average_daily_cost * 0.3)" | bc -l))); then\n  immediate_alert "Cost anomaly detected"\nfi\n'})}),"\n",(0,s.jsx)(t.h2,{id:"updated-authentication-requirements-mcp-2025-06-18",children:"Updated Authentication Requirements (MCP 2025-06-18)"}),"\n",(0,s.jsx)(t.p,{children:"The latest MCP specification now mandates proper OAuth implementation:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-typescript",children:'// Required: OAuth Resource Server pattern\nclass MCPServer {\n  private authConfig: OAuth2ResourceServer\n\n  constructor() {\n    this.authConfig = {\n      // Now required by spec\n      resourceServer: "https://your-auth-server.com",\n      requiredScopes: [\n        "mcp:tools:read",\n        "mcp:tools:execute",\n      ],\n      tokenValidation: "RFC8707", // Resource Indicators required\n    }\n  }\n\n  async validateRequest(\n    request: MCPRequest,\n  ): Promise<boolean> {\n    // Resource Indicators prevent token theft attacks\n    const token = this.extractToken(request)\n    return await this.validateWithResourceIndicators(token)\n  }\n}\n'})}),"\n",(0,s.jsx)(t.p,{children:"This addresses some authentication issues but doesn't solve tool description injection."}),"\n",(0,s.jsx)(t.h2,{id:"industry-security-recommendations",children:"Industry Security Recommendations"}),"\n",(0,s.jsx)(t.p,{children:"Security pros at OWASP and NIST keep hammering this: no prod creds in AI, period."}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"OWASP Top 10 for LLMs (2025):"}),(0,s.jsx)("sup",{children:(0,s.jsx)("a",{id:"ref-8",href:"#footnote-8",children:"8"})})]}),"\n",(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"LLM01: Prompt Injection"})," - #1 threat"]}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.strong,{children:"LLM02: Insecure Output Handling"})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.strong,{children:"LLM03: Training Data Poisoning"})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.strong,{children:"LLM04: Model Denial of Service"})}),"\n"]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"NIST AI Risk Management Framework:"}),(0,s.jsx)("sup",{children:(0,s.jsx)("a",{id:"ref-7",href:"#footnote-7",children:"7"})})]}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Treat AI systems as high-risk components"}),"\n",(0,s.jsx)(t.li,{children:"Implement continuous monitoring"}),"\n",(0,s.jsx)(t.li,{children:"Use defense-in-depth strategies"}),"\n",(0,s.jsx)(t.li,{children:"Plan for novel attack vectors"}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"the-bottom-line",children:"The Bottom Line"}),"\n",(0,s.jsx)(t.p,{children:"We're building systems that run commands based on natural language and connect to live infrastructure. The risks are well-known, the methods of attack are out there, and researchers are constantly finding new exploits."}),"\n",(0,s.jsx)(t.p,{children:"Fix this now, or enjoy the breach headlines later."}),"\n",(0,s.jsx)(t.h2,{id:"footnotes",children:"Footnotes"}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("a",{id:"footnote-1"}),(0,s.jsx)(t.strong,{children:"1."}),' Trail of Bits. "Jumping the Line: How MCP servers can attack you before you ever use them." April 21, 2025. ',(0,s.jsx)(o.h,{href:"https://blog.trailofbits.com/2025/04/21/jumping-the-line-how-mcp-servers-can-attack-you-before-you-ever-use-them/",children:(0,s.jsx)(t.a,{href:"https://blog.trailofbits.com/2025/04/21/jumping-the-line-how-mcp-servers-can-attack-you-before-you-ever-use-them/",children:"https://blog.trailofbits.com/2025/04/21/jumping-the-line-how-mcp-servers-can-attack-you-before-you-ever-use-them/"})})," ",(0,s.jsx)(o.h,{href:"#ref-1",children:"\u21a9"})]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("a",{id:"footnote-2"}),(0,s.jsx)(t.strong,{children:"2."}),' Trail of Bits. "How MCP servers can steal your conversation history." April 23, 2025. ',(0,s.jsx)(o.h,{href:"https://blog.trailofbits.com/2025/04/23/how-mcp-servers-can-steal-your-conversation-history/",children:(0,s.jsx)(t.a,{href:"https://blog.trailofbits.com/2025/04/23/how-mcp-servers-can-steal-your-conversation-history/",children:"https://blog.trailofbits.com/2025/04/23/how-mcp-servers-can-steal-your-conversation-history/"})})," ",(0,s.jsx)(o.h,{href:"#ref-2",children:"\u21a9"})]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("a",{id:"footnote-3"}),(0,s.jsx)(t.strong,{children:"3."}),' Trail of Bits. "Deceiving users with ANSI terminal codes in MCP." April 29, 2025. ',(0,s.jsx)(o.h,{href:"https://blog.trailofbits.com/2025/04/29/deceiving-users-with-ansi-terminal-codes-in-mcp/",children:(0,s.jsx)(t.a,{href:"https://blog.trailofbits.com/2025/04/29/deceiving-users-with-ansi-terminal-codes-in-mcp/",children:"https://blog.trailofbits.com/2025/04/29/deceiving-users-with-ansi-terminal-codes-in-mcp/"})})," ",(0,s.jsx)(o.h,{href:"#ref-3",children:"\u21a9"})]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("a",{id:"footnote-4"}),(0,s.jsx)(t.strong,{children:"4."}),' Trail of Bits. "Insecure credential storage plagues MCP." April 30, 2025. ',(0,s.jsx)(o.h,{href:"https://blog.trailofbits.com/2025/04/30/insecure-credential-storage-plagues-mcp/",children:(0,s.jsx)(t.a,{href:"https://blog.trailofbits.com/2025/04/30/insecure-credential-storage-plagues-mcp/",children:"https://blog.trailofbits.com/2025/04/30/insecure-credential-storage-plagues-mcp/"})})," ",(0,s.jsx)(o.h,{href:"#ref-4",children:"\u21a9"})]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("a",{id:"footnote-5"}),(0,s.jsx)(t.strong,{children:"5."}),' OWASP. "Top 10 for Large Language Model Applications (2025)." ',(0,s.jsx)(o.h,{href:"https://genai.owasp.org/resource/owasp-top-10-for-llm-applications-2025/",children:(0,s.jsx)(t.a,{href:"https://genai.owasp.org/resource/owasp-top-10-for-llm-applications-2025/",children:"https://genai.owasp.org/resource/owasp-top-10-for-llm-applications-2025/"})})," ",(0,s.jsx)(o.h,{href:"#ref-5",children:"\u21a9"})]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("a",{id:"footnote-6"}),(0,s.jsx)(t.strong,{children:"6."}),' Trail of Bits. "Provisioning cloud infrastructure the wrong way, but faster." August 27, 2024. ',(0,s.jsx)(o.h,{href:"https://blog.trailofbits.com/2024/08/27/provisioning-cloud-infrastructure-the-wrong-way-but-faster/",children:(0,s.jsx)(t.a,{href:"https://blog.trailofbits.com/2024/08/27/provisioning-cloud-infrastructure-the-wrong-way-but-faster/",children:"https://blog.trailofbits.com/2024/08/27/provisioning-cloud-infrastructure-the-wrong-way-but-faster/"})})," ",(0,s.jsx)(o.h,{href:"#ref-6",children:"\u21a9"})]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("a",{id:"footnote-7"}),(0,s.jsx)(t.strong,{children:"7."}),' NIST. "AI Risk Management Framework (AI RMF 1.0)." ',(0,s.jsx)(o.h,{href:"https://www.nist.gov/itl/ai-risk-management-framework",children:(0,s.jsx)(t.a,{href:"https://www.nist.gov/itl/ai-risk-management-framework",children:"https://www.nist.gov/itl/ai-risk-management-framework"})})," ",(0,s.jsx)(o.h,{href:"#ref-7",children:"\u21a9"})]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("a",{id:"footnote-8"}),(0,s.jsx)(t.strong,{children:"8."}),' OWASP. "Top 10 for LLMs (2025)." ',(0,s.jsx)(o.h,{href:"https://owasp.org/www-project-top-10-for-large-language-model-applications/",children:(0,s.jsx)(t.a,{href:"https://owasp.org/www-project-top-10-for-large-language-model-applications/",children:"https://owasp.org/www-project-top-10-for-large-language-model-applications/"})})," ",(0,s.jsx)(o.h,{href:"#ref-8",children:"\u21a9"})]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("a",{id:"footnote-9"}),(0,s.jsx)(t.strong,{children:"9."}),' CVE Database. "Prompt injection vulnerabilities." ',(0,s.jsx)(o.h,{href:"https://cve.mitre.org/",children:(0,s.jsx)(t.a,{href:"https://cve.mitre.org/",children:"https://cve.mitre.org/"})})," ",(0,s.jsx)(o.h,{href:"#ref-9",children:"\u21a9"})]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("a",{id:"footnote-10"}),(0,s.jsx)(t.strong,{children:"10."}),' Perez et al. "Prompt Injection Attacks Against GPT-3." arXiv:2108.04739. ',(0,s.jsx)(o.h,{href:"https://arxiv.org/abs/2108.04739",children:(0,s.jsx)(t.a,{href:"https://arxiv.org/abs/2108.04739",children:"https://arxiv.org/abs/2108.04739"})})," ",(0,s.jsx)(o.h,{href:"#ref-10",children:"\u21a9"})]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("a",{id:"footnote-11"}),(0,s.jsx)(t.strong,{children:"11."}),' Zou et al. "Universal and Transferable Adversarial Attacks on Aligned Language Models." arXiv:2307.15043. ',(0,s.jsx)(o.h,{href:"https://arxiv.org/abs/2307.15043",children:(0,s.jsx)(t.a,{href:"https://arxiv.org/abs/2307.15043",children:"https://arxiv.org/abs/2307.15043"})})," ",(0,s.jsx)(o.h,{href:"#ref-11",children:"\u21a9"})]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("a",{id:"footnote-12"}),(0,s.jsx)(t.strong,{children:"12."}),' Wei et al. "Jailbroken: How Does LLM Safety Training Fail?" arXiv:2307.02483. ',(0,s.jsx)(o.h,{href:"https://arxiv.org/abs/2307.02483",children:(0,s.jsx)(t.a,{href:"https://arxiv.org/abs/2307.02483",children:"https://arxiv.org/abs/2307.02483"})})," ",(0,s.jsx)(o.h,{href:"#ref-12",children:"\u21a9"})]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsxs)(t.em,{children:["\u2190 ",(0,s.jsx)(o.h,{href:"/blog/prevent-attacks-on-mcp",children:"Read Part 1: MCP Security Issues Nobody's Talking About"})]})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.em,{children:"Building MCP security tools or researching AI vulnerabilities? The documented threats are growing faster than the defenses. Let's change that."})}),"\n",(0,s.jsx)(t.h2,{id:"related-articles",children:"Related Articles"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.a,{href:"/blog/prevent-attacks-on-mcp",children:"MCP Security Issues Nobody's Talking About - Part 1"})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.a,{href:"/blog/ai-agent-best-practices",children:"AI Agent Best Practices: Maximizing Productivity with Forge"})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.a,{href:"/blog/mcp-spec-updates",children:"MCP New Specs: AI Agent Capabilities and Security Enhancements"})}),"\n"]})]})}function p(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(u,{...e})}):u(e)}},7617:(e,t,n)=>{n.d(t,{A:()=>i,h:()=>a});n(6540);var r=n(8774),s=n(4848);const i=({href:e,children:t,className:n="",external:i=!1,onClick:a})=>{const o=`text-tailCall-lightMode---primary-600 dark:text-tailCall-darkMode---primary-400 hover:text-tailCall-lightMode---primary-700 dark:hover:text-tailCall-darkMode---primary-300 transition-colors duration-300 ${n}`.trim();return i||e?.startsWith("http")?(0,s.jsx)("a",{href:e,className:o,target:"_blank",rel:"noopener noreferrer",onClick:a,children:t}):(0,s.jsx)(r.A,{to:e,className:o,onClick:a,children:t})},a=i},5348:(e,t,n)=>{n.d(t,{A:()=>a});var r=n(6540);const s={"elevenlabs-audio-player":"elevenlabs-audio-player_e04y","elevenlabs-audionative-widget":"elevenlabs-audionative-widget_SjXg"};var i=n(4848);const a=({publicUserId:e,projectId:t,size:n="small",textColorRgba:a,backgroundColorRgba:o,className:l="",children:c})=>((0,r.useEffect)((()=>{const e=document.createElement("script");return e.src="https://elevenlabs.io/player/audioNativeHelper.js",e.async=!0,document.body.appendChild(e),()=>{try{document.body.contains(e)&&document.body.removeChild(e)}catch(t){console.warn("Script removal failed:",t)}}}),[]),(0,i.jsx)("div",{className:`${s.elevenLabsAudioPlayer} ${l} dark:bg-tailCall-darkMode---neutral-400 rounded-xl my-5`,children:(0,i.jsx)("div",{id:"elevenlabs-audionative-widget","data-height":"small"===n?"90":"120","data-width":"100%","data-frameborder":"no","data-scrolling":"no","data-publicuserid":e,"data-playerurl":"https://elevenlabs.io/player/index.html","data-small":"small"===n?"True":"False","data-textcolor":a??"rgba(0, 0, 0, 1.0)","data-backgroundcolor":o??"#f5f3eb",...t&&{"data-projectid":t},children:c||"Elevenlabs AudioNative Player"})}))},8453:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>o});var r=n(6540);const s={},i=r.createContext(s);function a(e){const t=r.useContext(i);return r.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),r.createElement(i.Provider,{value:t},e.children)}},8390:e=>{e.exports=JSON.parse('{"permalink":"/blog/prevent-attacks-on-mcp-part2","source":"@site/blog/mcp-security-prevention-part-2.md","title":"MCP Security Prevention: Practical Strategies for AI Development - Part 2","description":"Dive into real-world MCP security vulnerabilities and discover actionable prevention strategies for AI development, focusing on prompt injection, cost-based attacks, and secure credential handling.","date":"2025-06-17T00:00:00.000Z","tags":[{"inline":true,"label":"Security","permalink":"/blog/tags/security"},{"inline":true,"label":"MCP","permalink":"/blog/tags/mcp"},{"inline":true,"label":"AI Safety","permalink":"/blog/tags/ai-safety"},{"inline":true,"label":"Best Practices","permalink":"/blog/tags/best-practices"},{"inline":true,"label":"Defense","permalink":"/blog/tags/defense"},{"inline":true,"label":"Prompt Injection","permalink":"/blog/tags/prompt-injection"},{"inline":true,"label":"Cloud Security","permalink":"/blog/tags/cloud-security"}],"readingTime":8.45,"hasTruncateMarker":true,"authors":[{"name":"Tushar","url":"https://github.com/tusharmath","social":[{"platform":"github","url":"https://github.com/tusharmath"},{"platform":"twitter","url":"https://twitter.com/tusharmath"},{"platform":"linkedin","url":"https://linkedin.com/in/tusharmath"}],"imageURL":"https://avatars.githubusercontent.com/u/194482?v=4","key":"tushar","page":null}],"frontMatter":{"slug":"prevent-attacks-on-mcp-part2","title":"MCP Security Prevention: Practical Strategies for AI Development - Part 2","description":"Dive into real-world MCP security vulnerabilities and discover actionable prevention strategies for AI development, focusing on prompt injection, cost-based attacks, and secure credential handling.","hide_table_of_contents":false,"authors":["tushar"],"tags":["Security","MCP","AI Safety","Best Practices","Defense","Prompt Injection","Cloud Security"],"date":"2025-06-17T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"MCP Security Crisis: Uncovering Vulnerabilities and Attack Vectors - Part 1","permalink":"/blog/prevent-attacks-on-mcp"},"nextItem":{"title":"When Google Sneezes, the Whole World Catches a Cold","permalink":"/blog/gcp-cloudflare-anthropic-outage"}}')}}]);